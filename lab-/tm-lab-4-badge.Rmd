---
title: 'Text Classification Badge'
subtitle: "LASER Institute TM Learning Lab 4"
author: "Dr. Shiyan Jiang"
date: "`r format(Sys.Date(),'%B %e, %Y')`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

![](img/tc.png){width="300"}

The final activity for each learning lab provides space to work with data and to reflect on how the concepts and techniques introduced in each lab might apply to your own research.

To earn a badge for each lab, you are required to respond to a set of prompts for two parts:Â 

-   In Part I, you will reflect on your understanding of key concepts and begin to think about potential next steps for your own study.

-   In Part II, you will create a simple data product in R that demonstrates your ability to apply a data analysis technique introduced in this learning lab.

### Part I: Reflect and Plan

Use the institutional library (e.g. [NCSU Library](https://www.lib.ncsu.edu/#articles)), [Google Scholar](https://scholar.google.com/) or search engine to locate a research article, presentation, or resource that applies text mining to an educational context or topic of interest. More specifically, **locate a text mining study that visualize text data.**

1.  Provide an APA citation for your selected study.

    -   

2.  How does text classification address research questions?

    -   

Draft a research question for a population you may be interested in studying, or that would be of interest to educational researchers, and that would require the collection of text data and answer the following questions:

1.  What text data would need to be collected?

    -   

2.  For what reason would text data need to be collected in order to address this question?

    -   

3.  Explain the analytical level at which these text data would need to be collected and analyzed.

    -   

### Part II: Data Product
We can use the chat-based API to perform a prompt-based text classification. You should use your own API and your own data to do text classification by changing the code in the following code chunk.

I highly recommend creating a new R script in your lab-4 folder to complete this task. When your code is ready to share, use the code chunk below to share the final code for your model and answer the questions that follow.

```{r, my-data-product}
# YOUR FINAL CODE HERE
library("httr")
library("jsonlite")

# Replace 'YOUR_API_KEY' with your actual API key
api_key <- "YOUR_API_KEY"

# Replace 'YOUR_PROMPT' with your classification task prompt
prompt <- "Classify whether text demonstrates critical data literacy skills. For example, the following text does not demonstrate critical data literacy: 'the graph shows me that there will be an extreme rainfall'. Thus the classification result is false. However, the following text demonstrates critical data literacy: 'I personally woudln't see Alaska being at risk to rising sea levels because of the cold and such, so I wonder why that is so. Also does snowfall fall under the same category as rainfall in this graph because that would explain why rainfll is also a risk in Alaska.' In this case, the classification result is true."
text_to_classify <- "this graph shows me when there is a extreme rainfall and if it  close to where you live."

# Use the chat-based API to get the classification result.
url <- "https://api.openai.com/v1/chat/completions"

headers <- c("Content-Type" = "application/json",
             "Authorization" = paste("Bearer", api_key))

payload <- list(
  "model" = "gpt-3.5-turbo",
  "messages" = list(
    list("role" = "system", "content" = prompt),
    list("role" = "user", "content" = text_to_classify)
  )
)

response <- POST(url, body = jsonlite::toJSON(payload), encode = "json", headers = headers)

# Extract the classification result
result <- content(response, as = "parsed")
classification_result <- result$choices[[length(result$choices)]]$message$content
```

### Knit & Submit

Congratulations, you've completed your Intro to text mining Badge! Complete the steps in the orientation to submit your work for review.